{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#coding:utf-8\n",
    "import glob\n",
    "import os\n",
    "import os.path\n",
    "import sys\n",
    "import subprocess\n",
    "import re\n",
    "import shutil\n",
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "class PrepareDataset(object):\n",
    "    \n",
    "    PATH_AVDATA = '/media/ikesan009/B418B4D718B499B6/CENSREC/avdata'\n",
    "    PATH_SAVE = '/media/ikesan009/B418B4D718B499B6/research/CENSREC/dataset'\n",
    "    PATH_LABEL_TABLE = '/media/ikesan009/B418B4D718B499B6/research/CENSREC/lib/label_table'\n",
    "    PATH_CONFIG = '/media/ikesan009/B418B4D718B499B6/research/CENSREC/lib/config.hcopy'\n",
    "    MFCC_DIM = 42\n",
    "    LEN_SEQ = 300\n",
    "    \n",
    "    #dirで指定されたパスが存在しない場合ディレクトリ作成\n",
    "    def make_dir(self,dir,format=False):\n",
    "        if not os.path.exists(dir):\n",
    "            os.makedirs(dir)\n",
    "        if format and os.path.exists(dir):\n",
    "            shutil.rmtree(dir)\n",
    "            \n",
    "    #コマンドライン操作\n",
    "    def run_command(self, cmd):\n",
    "        out = subprocess.run(cmd, stdout=subprocess.PIPE)\n",
    "        #print(out.stdout.decode())\n",
    "\n",
    "    #HCopy操作\n",
    "    def run_hcopy(self, path_config, path_wav, path_mfc):\n",
    "        cmd = ['HCopy', '-C', path_config, path_wav, path_mfc]\n",
    "        self.run_command(cmd)\n",
    "        \n",
    "    #HList操作\n",
    "    def run_hlist(self, n_dim, path_mfc, path_txt):\n",
    "        cmd = ['HList', '-i', str(n_dim), path_mfc]\n",
    "        out = subprocess.run(cmd, stdout=subprocess.PIPE)\n",
    "        with open(path_txt, mode='w', encoding='utf-8') as f:\n",
    "            f.write(out.stdout.decode())\n",
    "        \n",
    "    #ゼロパディング\n",
    "    def zero_padding(self, x, len_seq, dim_step):\n",
    "        size_target = len_seq * dim_step\n",
    "        x = np.append(x, np.zeros(size_target - x.size))\n",
    "        return x\n",
    "        \n",
    "    #ファイル移動など\n",
    "    def prepare_dataset(self):\n",
    "        print('running prepare_dataset...')\n",
    "        pbar1 = tqdm(os.listdir(self.PATH_AVDATA))\n",
    "        for dir1 in pbar1:\n",
    "            pbar1.set_description(\"Processing :\"+dir1)\n",
    "            path1 = os.path.join(self.PATH_AVDATA, dir1)\n",
    "\n",
    "            for dir2 in tqdm(os.listdir(path1)):\n",
    "                path2 = os.path.join(path1, dir2)\n",
    "\n",
    "                for wav in glob.glob(path2+'/*.wav'):\n",
    "                    fname = os.path.splitext(os.path.basename(wav))\n",
    "                    label = re.findall('_.*' , fname[0])\n",
    "                    \n",
    "                    if len(label[0][1:]) < 3:\n",
    "                        dir_save = os.path.join(self.PATH_SAVE, dir1, label[0][1:])\n",
    "                        self.make_dir(dir_save)\n",
    "                        shutil.copyfile(wav, os.path.join(dir_save, fname[0]+fname[1]))\n",
    "        print('prepare_dataset was Done.')\n",
    "                         \n",
    "    #ディレクトリラベル付け\n",
    "    def rename_dir_to_label(self, path_dir, path_dic):\n",
    "        print('running rename_dir_to_label...')\n",
    "        if os.path.exists(path_dic):\n",
    "            f = open(path_dic,'rb')\n",
    "            label_dic = pickle.load(f)\n",
    "            \n",
    "        else:\n",
    "            label_dic = {}\n",
    "            i = 0\n",
    "            for dir1 in os.listdir(path_dir):\n",
    "                path1 = os.path.join(self.PATH_SAVE, dir1)\n",
    "                for dir2 in os.listdir(path1):\n",
    "                    if not dir2 in label_dic:\n",
    "                        label_dic[dir2] = i\n",
    "                        i += 1\n",
    "\n",
    "            f = open(path_dic,'wb')\n",
    "            pickle.dump(label_dic,f)\n",
    "            f.close\n",
    "        \n",
    "        for dir1 in os.listdir(path_dir):\n",
    "            path1 = os.path.join(self.PATH_SAVE, dir1)\n",
    "            for dir2 in os.listdir(path1):\n",
    "                path2 = os.path.join(path1, dir2)\n",
    "                rname = os.path.join(path1, str(label_dic[dir2]))\n",
    "                os.rename(path2, rname)\n",
    "                \n",
    "        print('rename_to_dir_to_label was Done.')\n",
    "                \n",
    "    #MFCC抽出\n",
    "    def extract_mfcc(self, path_dir):\n",
    "        print('running extract_mfcc...')\n",
    "        pbar1 = tqdm(os.listdir(path_dir))\n",
    "        for dir1 in pbar1:\n",
    "            pbar1.set_description(\"Processing :\"+dir1)\n",
    "            path1 = os.path.join(self.PATH_SAVE, dir1)\n",
    "            for dir2 in tqdm(os.listdir(path1)):\n",
    "                path2 = os.path.join(path1, dir2)\n",
    "                for wav in glob.glob(path2+'/*.wav'):\n",
    "                    fname = os.path.splitext(os.path.basename(wav))\n",
    "                    #self.run_hcopy(self.PATH_CONFIG, wav, os.path.join(path2, fname[0]+'.mfc'))\n",
    "                    self.run_hlist(self.MFCC_DIM, os.path.join(path2, fname[0]+'.mfc'), os.path.join(path2, fname[0]+'.mfctxt'))\n",
    "        print('extract_mfcc was Done.')\n",
    "    \n",
    "    #TFRecordsファイルの作成\n",
    "    def make_TFR(self, path_dir, path_tfr):\n",
    "        print('running make_TFR...')\n",
    "        pbar1 = tqdm(os.listdir(path_dir))\n",
    "        with tf.python_io.TFRecordWriter(path_tfr) as writer:\n",
    "            for dir1 in pbar1:\n",
    "                pbar1.set_description(\"Processing :\"+dir1)\n",
    "                path1 = os.path.join(path_dir, dir1)\n",
    "                for mfctxt in glob.glob(path1+'/*.mfctxt'):\n",
    "                    with open(mfctxt, encoding='utf-8') as f:\n",
    "                        lines = f.readlines()[1:-1]\n",
    "                        data = np.array([])\n",
    "                        for line in lines:\n",
    "                            txt = line.strip()\n",
    "                            txt = txt.split()\n",
    "                            for val in txt[1:]:\n",
    "                                data = np.append(data, float(val))\n",
    "                        data = self.zero_padding(data, self.LEN_SEQ, self.MFCC_DIM)\n",
    "                        data = data.astype(np.float32)\n",
    "                        data = np.reshape(data, [-1, self.MFCC_DIM])\n",
    "                        record = tf.train.Example(features=tf.train.Features(feature={\n",
    "                            \"label\": tf.train.Feature(\n",
    "                                int64_list=tf.train.Int64List(value=[int(dir1)])),\n",
    "                            \"data\": tf.train.Feature(\n",
    "                                bytes_list=tf.train.BytesList(value=[data.tobytes()])),\n",
    "                        }))\n",
    "                        writer.write(record.SerializeToString())\n",
    "                        \n",
    "        print('make_TFR was Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing :0:   0%|          | 0/22 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running make_TFR...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing :9: 100%|██████████| 22/22 [00:19<00:00,  1.10it/s] \n",
      "Processing :0:   0%|          | 0/22 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make_TFR was Done.\n",
      "running make_TFR...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing :9: 100%|██████████| 22/22 [00:17<00:00,  1.23it/s] \n",
      "Processing :0:   0%|          | 0/22 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make_TFR was Done.\n",
      "running make_TFR...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing :11:  14%|█▎        | 3/22 [00:01<00:10,  1.78it/s]"
     ]
    }
   ],
   "source": [
    "pd = PrepareDataset()\n",
    "#pd.prepare_dataset()\n",
    "#pd.rename_dir_to_label(pd.PATH_SAVE, pd.PATH_LABEL_TABLE)\n",
    "#pd.extract_mfcc(pd.PATH_SAVE)\n",
    "pd.make_TFR(os.path.join(pd.PATH_SAVE, 'train-male'), os.path.join(pd.PATH_SAVE, 'train-male.tfrecords'))\n",
    "pd.make_TFR(os.path.join(pd.PATH_SAVE, 'train-female'), os.path.join(pd.PATH_SAVE, 'train-female.tfrecords'))\n",
    "pd.make_TFR(os.path.join(pd.PATH_SAVE, 'test-male'), os.path.join(pd.PATH_SAVE, 'test-male.tfrecords'))\n",
    "pd.make_TFR(os.path.join(pd.PATH_SAVE, 'test-female'), os.path.join(pd.PATH_SAVE, 'test-female.tfrecords'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
